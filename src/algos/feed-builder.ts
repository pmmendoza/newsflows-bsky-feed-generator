import { Kysely } from 'kysely'
import { QueryParams, OutputSchema as AlgoOutput } from '../lexicon/types/app/bsky/feed/getFeedSkeleton'
import { DatabaseSchema } from '../db/schema'
import { AppContext } from '../config'
import { SkeletonFeedPost } from '../lexicon/types/app/bsky/feed/defs'

// Type definition for FeedGenerator handler
export type FeedGenerator = (ctx: AppContext, params: QueryParams, requesterDid: string) => Promise<AlgoOutput>

// Type for the query builder functions
export type QueryBuilder = (
  db: Kysely<DatabaseSchema>,
  timeLimit: string,
  requesterFollows: string[],
  cursorOffset: number,
  limit: number
) => any

// Interface for the feed generator options
export interface FeedGeneratorOptions {
  shortname: string
  ctx: AppContext
  params: QueryParams
  requesterDid: string
  buildPublisherQuery: QueryBuilder
  buildFollowsQuery: QueryBuilder
}

// Main function to build a feed
export async function buildFeed({
  shortname,
  ctx,
  params,
  requesterDid,
  buildPublisherQuery,
  buildFollowsQuery
}: FeedGeneratorOptions) {
  console.log(`[${new Date().toISOString()}] - Feed ${shortname} requested by ${requesterDid}`);
  const limit = Math.floor(params.limit / 3); // 1/3 from news + 2/3 other
  const requesterFollows = await getFollows(requesterDid, ctx.db)
  
  // don't consider posts older than time limit hours
  const engagementTimeHours = process.env.ENGAGEMENT_TIME_HOURS ?
    parseInt(process.env.ENGAGEMENT_TIME_HOURS, 10) : 72;
  const timeLimit = new Date(Date.now() - engagementTimeHours * 60 * 60 * 1000).toISOString();

  // Parse cursor if provided
  let cursorOffset = 0;
  if (params.cursor) {
    cursorOffset = parseInt(params.cursor, 10);
  }

  // Build the queries using the provided builder functions
  const publisherPostsQuery = buildPublisherQuery(
    ctx.db,
    timeLimit,
    requesterFollows,
    cursorOffset,
    limit
  );

  const otherPostsQuery = buildFollowsQuery(
    ctx.db,
    timeLimit,
    requesterFollows,
    cursorOffset,
    limit * 2
  );

  // Execute both queries in parallel
  const [publisherPosts, otherPosts] = await Promise.all([
    publisherPostsQuery.execute(),
    otherPostsQuery.execute()
  ]);

  console.log(`[${new Date().toISOString()}] - Feed ${shortname} retrieved ${publisherPosts.length} publisher posts and ${otherPosts.length} other posts`);

  // Merge both post lists in a 1:2 pattern (1 publisher post, 2 other posts)
  const feed: SkeletonFeedPost[] = [];
  let publisherIndex = 0;
  let otherIndex = 0;

  while (publisherIndex < publisherPosts.length || otherIndex < otherPosts.length) {
    // Add 1 publisher post
    if (publisherIndex < publisherPosts.length) {
      feed.push({ post: publisherPosts[publisherIndex].uri });
      publisherIndex++;
    }

    // Add 2 other posts
    for (let i = 0; i < 2 && otherIndex < otherPosts.length; i++) {
      feed.push({ post: otherPosts[otherIndex].uri });
      otherIndex++;
    }
  }

  // Calculate cursor based on the offset for the next page
  let cursor: string | undefined;
  const totalPostsReturned = publisherPosts.length + otherPosts.length;
  if (totalPostsReturned > 0) {
    // Set the next offset to current offset + number of posts returned
    cursor = (cursorOffset + limit * 2).toString();
  }

  // Log request to database (non-blocking)
  setTimeout(async () => {
    try {
      const timestamp = new Date().toISOString();
      const requestedLimit =
        typeof params.limit === 'number' && Number.isFinite(params.limit)
          ? params.limit
          : null
      const requestInsertResult = await ctx.db
        .insertInto('request_log')
        .values({
          algo: shortname,
          requester_did: requesterDid,
          timestamp: timestamp,
          cursor_in: params.cursor ?? null,
          cursor_out: cursor ?? null,
          requested_limit: requestedLimit,
          publisher_count: publisherPosts.length,
          follows_count: otherPosts.length,
          result_count: feed.length,
        })
        .returning('id')
        .executeTakeFirstOrThrow();

      if (feed.length > 0) {
        const postValues = feed.map((post, index) => ({
          position: index + 1,
          request_id: requestInsertResult.id as number,
          post_uri: post.post
        }));

        // Use batch insert for better performance
        await ctx.db
          .insertInto('request_posts')
          .values(postValues)
          .execute();
      }
    } catch (error) {
      console.error('Error logging request:', error);
    }
  }, 0);

  return {
    cursor,
    feed,
  };
}

// Helper function to get follows
async function getFollows(actor: string, db: any): Promise<string[]> {
  // Import the function dynamically to avoid circular imports
  const { getFollows } = await import('../util/queries');
  return getFollows(actor, db);
}
